# ğŸ¤Ÿ Sign Language Recognition System (MediaPipe + MLPClassifier + OpenCV)

An AI-powered system that recognizes American Sign Language (Aâ€“E) in real-time using hand landmarks from MediaPipe and a machine learning classifier. This project helps bridge communication gaps for the hearing and speech impaired.

---

# ğŸš€ Features

- Real-time hand gesture detection using webcam
- Collect labeled hand landmarks for Aâ€“E gestures
- Train an MLPClassifier model on collected hand landmark data
- Predict and display live sign labels in webcam feed
- Supports custom dataset expansion

---

# ğŸ› ï¸ Tech Stack

- Python
- MediaPipe (for hand tracking)
- OpenCV (for webcam interaction)
- scikit-learn (MLPClassifier)
- NumPy, Pandas (data processing)

---

# ğŸ“‚ Folder Structure

sign_language_recognition/
â”œâ”€â”€ app.py # (Optional) For future Streamlit app
â”œâ”€â”€ mediapipe_hand_capture.py # Data collection script
â”œâ”€â”€ train_model.py # Model training script
â”œâ”€â”€ predict_webcam.py # Real-time sign prediction
â”œâ”€â”€ predict_sign.py # Predict from saved image or CSV
â”œâ”€â”€ check_labels.py # Check label distribution
â”œâ”€â”€ inspect_data.py # Inspect CSV data quality
â”œâ”€â”€ test_cam.py # Webcam test
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ data/ # Collected hand landmark CSV
â”‚ â””â”€â”€ sign_data.csv
â”œâ”€â”€ model/ # Trained model
â”‚ â””â”€â”€ sign_model.pkl

---

# ğŸ“¸ Sample Output

- ğŸ–ï¸ Hand landmarks detected using MediaPipe
- âœ… Sign A to E predicted in real-time
- ğŸ“Š Model accuracy shown after training

---

# ğŸ™‹â€â™‚ï¸ Created By

Mohammed Salman
ğŸ“§ mohammed.salman.p.2004@gmail.com
ğŸ”— LinkedIn â€¢ ğŸŒ GitHub

---

# ğŸ“œ License

This project is licensed under the MIT License.
